* Calculate entropy of a section
** 
   | X1 | X2 | x3 | class |
   |----+----+----+-------|
   |  1 |  2 |  3 | A     |
   |  1 |  4 |  5 | A     |
   |  2 |  2 |  5 | B     |
   |  5 |  2 |  1 | B     |
   |  3 |  5 |  1 | A     |

Equation:
p = probability
H(S) = -SUM p(c) log2 p(c):
= - (p(A)log2P(A) + p(B)log2P(B))
= - p(A)log2P(A) - p(B)log2p(B)
= - 3/5 * log2(3/5) - 2/5 * log2(2/5)

#+BEGIN_SRC python :results output
  import math
  def entropy(P1, P2):
        entropy = -P1 * math.log(P1, 2) - P2 * math.log(P2, 2)
        print entropy
  entropy(3.0/5, 2.0/5)
#+END_SRC 

#+RESULTS:
: 0.970950594455
  

In order to figure out each entropy for the attributes then you can decide based on the lowest level of entropy. Then you average both values. We need to do a weighted average of the two. Multiply by the probability.

#+BEGIN_SRC python :results output

#+END_SRC 
